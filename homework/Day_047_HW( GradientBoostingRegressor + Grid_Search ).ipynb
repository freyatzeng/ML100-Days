{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets,metrics\n",
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417300</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>-1.286636</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>0.413263</td>\n",
       "      <td>-0.119895</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.665949</td>\n",
       "      <td>-1.457558</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.074499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.414859</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>0.194082</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.491953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.414861</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>1.281446</td>\n",
       "      <td>-0.265549</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.396035</td>\n",
       "      <td>-1.207532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414270</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.015298</td>\n",
       "      <td>-0.809088</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.415751</td>\n",
       "      <td>-1.360171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410003</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.227362</td>\n",
       "      <td>-0.510674</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.025487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417300  0.284548 -1.286636 -0.272329 -0.144075  0.413263 -0.119895   \n",
       "1 -0.414859 -0.487240 -0.592794 -0.272329 -0.739530  0.194082  0.366803   \n",
       "2 -0.414861 -0.487240 -0.592794 -0.272329 -0.739530  1.281446 -0.265549   \n",
       "3 -0.414270 -0.487240 -1.305586 -0.272329 -0.834458  1.015298 -0.809088   \n",
       "4 -0.410003 -0.487240 -1.305586 -0.272329 -0.834458  1.227362 -0.510674   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.140075 -0.981871 -0.665949 -1.457558  0.440616 -1.074499  \n",
       "1  0.556609 -0.867024 -0.986353 -0.302794  0.440616 -0.491953  \n",
       "2  0.556609 -0.867024 -0.986353 -0.302794  0.396035 -1.207532  \n",
       "3  1.076671 -0.752178 -1.105022  0.112920  0.415751 -1.360171  \n",
       "4  1.076671 -0.752178 -1.105022  0.112920  0.440616 -1.025487  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "df2 = (df - df.mean()) / df.std() #z轉換\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuacy= 0.88335\n",
      "MSE= 8.16840\n"
     ]
    }
   ],
   "source": [
    "X = df2.values  #用.values取\n",
    "Y = boston.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,random_state=42)\n",
    "\n",
    "GBR = GradientBoostingRegressor()\n",
    "GBR.fit(x_train,y_train)\n",
    "y_pred = GBR.predict(x_test)\n",
    "\n",
    "print(f'Accuacy= {metrics.r2_score(y_test, y_pred):.5f}')\n",
    "print(f'MSE= {metrics.mean_squared_error(y_test,y_pred):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 16.227108 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.9s finished\n"
     ]
    }
   ],
   "source": [
    "tStart = time.time()\n",
    "# 設定要訓練的超參數組合\n",
    "learning_rate = [0.03, 0.05, 0.1, 0.15, 0.2] #default=0.1\n",
    "n_estimators = [50, 100, 200, 300, 400]      #default=100\n",
    "max_depth = [1, 3, 5, 7]                     #default=3\n",
    "param_grid = dict(n_estimators = n_estimators, max_depth = max_depth, learning_rate = learning_rate)\n",
    "\n",
    "# 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "grid_search = GridSearchCV(GBR, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "# 開始搜尋最佳參數\n",
    "grid_result = grid_search.fit(x_train,y_train)\n",
    "\n",
    "tEnd = time.time()\n",
    "print(\"It cost %f sec\" % (tEnd - tStart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: -12.678452 using {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# 印出最佳結果與最佳參數\n",
    "print('Best Accuracy: %f using %s' % (grid_result.best_score_ , grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC= 0.88502\n",
      "MSE= 8.05164\n"
     ]
    }
   ],
   "source": [
    "#用最佳重新建模\n",
    "GBR_best = GradientBoostingRegressor(learning_rate = grid_result.best_params_['learning_rate'], \n",
    "                                     max_depth = grid_result.best_params_['max_depth'], \n",
    "                                     n_estimators = grid_result.best_params_['n_estimators'])\n",
    "GBR_best.fit(x_train,y_train)\n",
    "Y_pred = GBR_best.predict(x_test)\n",
    "print(f'ACC= {metrics.r2_score(y_test,Y_pred):.5f}')\n",
    "print(f'MSE= {metrics.mean_squared_error(y_test,Y_pred):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
